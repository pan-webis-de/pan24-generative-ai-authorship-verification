{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2c7907-2894-4061-a801-5c854106ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from scipy.stats import gmean\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530112bd-7ae5-4672-9b4b-486f836e33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAM_TO_SUBMISSIONS = json.load(open('teams-to-systems.json'))\n",
    "task = 'generative-ai-authorship-verification-panclef-2024'\n",
    "DATASETS = [\n",
    "    'pan24-generative-authorship-test-20240502-test', 'pan24-generative-authorship-test-b-20240506-test', 'pan24-generative-authorship-news-test-c-20240506-test',\n",
    "    'pan24-generative-authorship-news-test-d-20240506-test', 'pan24-generative-authorship-news-test-e-20240506-test', 'pan24-generative-authorship-news-test-f-20240514-test',\n",
    "    'pan24-generative-authorship-news-test-g-20240529-test', 'pan24-generative-authorship-news-test-h-20240521-test', 'pan24-generative-authorship-eloquent-20240523-test'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea166c1-f4a5-4251-9629-950dbbab30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "evaluation_scores = json.load(open('evaluation-scores.json', 'r'))\n",
    "\n",
    "for team, approaches in TEAM_TO_SUBMISSIONS.items():\n",
    "    for approach in approaches:\n",
    "        tmp = {'approach': approach, 'team': team}\n",
    "        scores = []\n",
    "        for dataset in DATASETS:\n",
    "            try:\n",
    "                score = evaluation_scores[team][approach][dataset]['mean']\n",
    "                tmp[dataset + ' (Mean)'] = score\n",
    "                scores += [score]\n",
    "            except:\n",
    "                pass\n",
    "        tmp['arithmetic_mean'] = mean(scores)\n",
    "        tmp['geometric_mean'] = gmean(scores)\n",
    "        df += [tmp]\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c115cda-b719-40b7-a727-e39e8e94127e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>team</th>\n",
       "      <th>pan24-generative-authorship-test-20240502-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-test-b-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-c-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-d-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-e-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-f-20240514-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-g-20240529-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-h-20240521-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-eloquent-20240523-test (Mean)</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>geometric_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staff-trunk</td>\n",
       "      <td>marsan</td>\n",
       "      <td>0.998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.975125</td>\n",
       "      <td>0.974429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>plain-fortress</td>\n",
       "      <td>you-shun-you-de</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.962222</td>\n",
       "      <td>0.961536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>charitable-mole_v3</td>\n",
       "      <td>you-shun-you-de</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.962222</td>\n",
       "      <td>0.961536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>logistic-fsu</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.952556</td>\n",
       "      <td>0.951345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>gritty-producer</td>\n",
       "      <td>g-fosunlpteam</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.936270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pizzicato-radian</td>\n",
       "      <td>foshan-university-of-guangdong</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.367444</td>\n",
       "      <td>0.365983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cnn_fanle</td>\n",
       "      <td>turtlewu</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.330667</td>\n",
       "      <td>0.295914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>several-fleet</td>\n",
       "      <td>lam</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.283125</td>\n",
       "      <td>0.281817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>transform_fanle</td>\n",
       "      <td>turtlewu</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.269556</td>\n",
       "      <td>0.215452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>independent-net</td>\n",
       "      <td>foshan-university-of-guangdong</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.253444</td>\n",
       "      <td>0.253433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               approach                            team  \\\n",
       "1           staff-trunk                          marsan   \n",
       "57       plain-fortress                 you-shun-you-de   \n",
       "58   charitable-mole_v3                 you-shun-you-de   \n",
       "102        logistic-fsu                        baseline   \n",
       "63      gritty-producer                   g-fosunlpteam   \n",
       "..                  ...                             ...   \n",
       "4      pizzicato-radian  foshan-university-of-guangdong   \n",
       "18            cnn_fanle                        turtlewu   \n",
       "42        several-fleet                             lam   \n",
       "17      transform_fanle                        turtlewu   \n",
       "2       independent-net  foshan-university-of-guangdong   \n",
       "\n",
       "     pan24-generative-authorship-test-20240502-test (Mean)  \\\n",
       "1                                                0.998       \n",
       "57                                               0.990       \n",
       "58                                               0.990       \n",
       "102                                              0.972       \n",
       "63                                               0.966       \n",
       "..                                                 ...       \n",
       "4                                                0.372       \n",
       "18                                               0.332       \n",
       "42                                               0.253       \n",
       "17                                               0.224       \n",
       "2                                                0.255       \n",
       "\n",
       "     pan24-generative-authorship-test-b-20240506-test (Mean)  \\\n",
       "1                                                  NaN         \n",
       "57                                               0.989         \n",
       "58                                               0.989         \n",
       "102                                              0.963         \n",
       "63                                               0.966         \n",
       "..                                                 ...         \n",
       "4                                                0.388         \n",
       "18                                               0.346         \n",
       "42                                               0.256         \n",
       "17                                               0.231         \n",
       "2                                                0.254         \n",
       "\n",
       "     pan24-generative-authorship-news-test-c-20240506-test (Mean)  \\\n",
       "1                                                0.983              \n",
       "57                                               0.965              \n",
       "58                                               0.965              \n",
       "102                                              0.978              \n",
       "63                                               0.990              \n",
       "..                                                 ...              \n",
       "4                                                0.347              \n",
       "18                                               0.092              \n",
       "42                                               0.292              \n",
       "17                                               0.038              \n",
       "2                                                0.252              \n",
       "\n",
       "     pan24-generative-authorship-news-test-d-20240506-test (Mean)  \\\n",
       "1                                                0.955              \n",
       "57                                               0.933              \n",
       "58                                               0.933              \n",
       "102                                              0.975              \n",
       "63                                               0.959              \n",
       "..                                                 ...              \n",
       "4                                                0.319              \n",
       "18                                               0.274              \n",
       "42                                               0.256              \n",
       "17                                               0.147              \n",
       "2                                                0.252              \n",
       "\n",
       "     pan24-generative-authorship-news-test-e-20240506-test (Mean)  \\\n",
       "1                                                0.986              \n",
       "57                                               0.936              \n",
       "58                                               0.936              \n",
       "102                                              0.987              \n",
       "63                                               0.743              \n",
       "..                                                 ...              \n",
       "4                                                0.391              \n",
       "18                                               0.210              \n",
       "42                                               0.309              \n",
       "17                                               0.218              \n",
       "2                                                0.252              \n",
       "\n",
       "     pan24-generative-authorship-news-test-f-20240514-test (Mean)  \\\n",
       "1                                                0.993              \n",
       "57                                               0.989              \n",
       "58                                               0.989              \n",
       "102                                              0.958              \n",
       "63                                               0.993              \n",
       "..                                                 ...              \n",
       "4                                                0.429              \n",
       "18                                               0.363              \n",
       "42                                               0.291              \n",
       "17                                               0.277              \n",
       "2                                                0.252              \n",
       "\n",
       "     pan24-generative-authorship-news-test-g-20240529-test (Mean)  \\\n",
       "1                                                1.000              \n",
       "57                                               0.999              \n",
       "58                                               0.999              \n",
       "102                                              0.970              \n",
       "63                                               0.996              \n",
       "..                                                 ...              \n",
       "4                                                0.322              \n",
       "18                                               0.336              \n",
       "42                                               0.272              \n",
       "17                                               0.233              \n",
       "2                                                0.256              \n",
       "\n",
       "     pan24-generative-authorship-news-test-h-20240521-test (Mean)  \\\n",
       "1                                                0.887              \n",
       "57                                               0.883              \n",
       "58                                               0.883              \n",
       "102                                              0.826              \n",
       "63                                               0.863              \n",
       "..                                                 ...              \n",
       "4                                                0.365              \n",
       "18                                               0.676              \n",
       "42                                                 NaN              \n",
       "17                                               0.713              \n",
       "2                                                0.258              \n",
       "\n",
       "     pan24-generative-authorship-eloquent-20240523-test (Mean)  \\\n",
       "1                                                0.999           \n",
       "57                                               0.976           \n",
       "58                                               0.976           \n",
       "102                                              0.944           \n",
       "63                                               0.984           \n",
       "..                                                 ...           \n",
       "4                                                0.374           \n",
       "18                                               0.347           \n",
       "42                                               0.336           \n",
       "17                                               0.345           \n",
       "2                                                0.250           \n",
       "\n",
       "     arithmetic_mean  geometric_mean  \n",
       "1           0.975125        0.974429  \n",
       "57          0.962222        0.961536  \n",
       "58          0.962222        0.961536  \n",
       "102         0.952556        0.951345  \n",
       "63          0.940000        0.936270  \n",
       "..               ...             ...  \n",
       "4           0.367444        0.365983  \n",
       "18          0.330667        0.295914  \n",
       "42          0.283125        0.281817  \n",
       "17          0.269556        0.215452  \n",
       "2           0.253444        0.253433  \n",
       "\n",
       "[103 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('arithmetic_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be5525ce-97d3-42fd-9232-e934aeab8662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>team</th>\n",
       "      <th>pan24-generative-authorship-test-20240502-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-test-b-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-c-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-d-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-e-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-f-20240514-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-g-20240529-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-h-20240521-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-eloquent-20240523-test (Mean)</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>geometric_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staff-trunk</td>\n",
       "      <td>marsan</td>\n",
       "      <td>0.998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.975125</td>\n",
       "      <td>0.974429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>plain-fortress</td>\n",
       "      <td>you-shun-you-de</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.962222</td>\n",
       "      <td>0.961536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>charitable-mole_v3</td>\n",
       "      <td>you-shun-you-de</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.962222</td>\n",
       "      <td>0.961536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>logistic-fsu</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.952556</td>\n",
       "      <td>0.951345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>final-run8-gnnllm_stylofeat-fullpartitionB</td>\n",
       "      <td>iimasnlp</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.939875</td>\n",
       "      <td>0.937582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>gritty-producer</td>\n",
       "      <td>g-fosunlpteam</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.936270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>final-run7-gnnllm_llmft_stylofeat-fullpartitionA</td>\n",
       "      <td>iimasnlp</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.935375</td>\n",
       "      <td>0.932430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>final-run10-gnnllm_llmft_stylofeat-fullpartitionB</td>\n",
       "      <td>iimasnlp</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.925748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>final-run6-gnnllm_llmft_stylofeat-fullpartitionA</td>\n",
       "      <td>iimasnlp</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.922875</td>\n",
       "      <td>0.920002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>blistering-moss</td>\n",
       "      <td>lam</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.920556</td>\n",
       "      <td>0.916360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>muffled-stock</td>\n",
       "      <td>drocks</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.914778</td>\n",
       "      <td>0.910603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>final-run5-gnnllm_stylofeat-fullpartitionA</td>\n",
       "      <td>iimasnlp</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.911375</td>\n",
       "      <td>0.908839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>vicious-artifact</td>\n",
       "      <td>aida</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.898889</td>\n",
       "      <td>0.893479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>corporate-burn</td>\n",
       "      <td>aida</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.898778</td>\n",
       "      <td>0.893460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>lazy-iteration</td>\n",
       "      <td>g-fosunlpteam</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.897444</td>\n",
       "      <td>0.889619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>marinated-pantone</td>\n",
       "      <td>ap-team</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.894333</td>\n",
       "      <td>0.887934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>swarm-apartment_v1</td>\n",
       "      <td>you-shun-you-de</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.888778</td>\n",
       "      <td>0.883672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>merciless-broth</td>\n",
       "      <td>fosu-stu</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.891111</td>\n",
       "      <td>0.882329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>merciless-lease</td>\n",
       "      <td>verification-team</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.874556</td>\n",
       "      <td>0.865489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>method2</td>\n",
       "      <td>no-999</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.875778</td>\n",
       "      <td>0.864057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>final-run4-gnnllm_llmft_stylofeat-partitionB</td>\n",
       "      <td>iimasnlp</td>\n",
       "      <td>0.992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.877571</td>\n",
       "      <td>0.859990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>bitter-metaphor</td>\n",
       "      <td>huangbaijian</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.872875</td>\n",
       "      <td>0.855725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>bayes-fsu-count-vectorizer</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.864333</td>\n",
       "      <td>0.853668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>bayes-fsu-tfidf-vectorizer</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.854444</td>\n",
       "      <td>0.851872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>breezy-style</td>\n",
       "      <td>drocks</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.857889</td>\n",
       "      <td>0.843111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              approach               team  \\\n",
       "1                                          staff-trunk             marsan   \n",
       "57                                      plain-fortress    you-shun-you-de   \n",
       "58                                  charitable-mole_v3    you-shun-you-de   \n",
       "102                                       logistic-fsu           baseline   \n",
       "29          final-run8-gnnllm_stylofeat-fullpartitionB           iimasnlp   \n",
       "63                                     gritty-producer      g-fosunlpteam   \n",
       "35    final-run7-gnnllm_llmft_stylofeat-fullpartitionA           iimasnlp   \n",
       "37   final-run10-gnnllm_llmft_stylofeat-fullpartitionB           iimasnlp   \n",
       "34    final-run6-gnnllm_llmft_stylofeat-fullpartitionA           iimasnlp   \n",
       "39                                     blistering-moss                lam   \n",
       "76                                       muffled-stock             drocks   \n",
       "33          final-run5-gnnllm_stylofeat-fullpartitionA           iimasnlp   \n",
       "65                                    vicious-artifact               aida   \n",
       "66                                      corporate-burn               aida   \n",
       "62                                      lazy-iteration      g-fosunlpteam   \n",
       "75                                   marinated-pantone            ap-team   \n",
       "56                                  swarm-apartment_v1    you-shun-you-de   \n",
       "72                                     merciless-broth           fosu-stu   \n",
       "70                                     merciless-lease  verification-team   \n",
       "24                                             method2             no-999   \n",
       "32        final-run4-gnnllm_llmft_stylofeat-partitionB           iimasnlp   \n",
       "44                                     bitter-metaphor       huangbaijian   \n",
       "101                         bayes-fsu-count-vectorizer           baseline   \n",
       "100                         bayes-fsu-tfidf-vectorizer           baseline   \n",
       "78                                        breezy-style             drocks   \n",
       "\n",
       "     pan24-generative-authorship-test-20240502-test (Mean)  \\\n",
       "1                                                0.998       \n",
       "57                                               0.990       \n",
       "58                                               0.990       \n",
       "102                                              0.972       \n",
       "29                                               0.974       \n",
       "63                                               0.966       \n",
       "35                                               0.990       \n",
       "37                                               0.987       \n",
       "34                                               0.970       \n",
       "39                                               0.990       \n",
       "76                                               0.973       \n",
       "33                                               0.964       \n",
       "65                                               0.975       \n",
       "66                                               0.976       \n",
       "62                                               0.951       \n",
       "75                                               0.954       \n",
       "56                                               0.946       \n",
       "72                                               0.949       \n",
       "70                                               0.971       \n",
       "24                                               0.932       \n",
       "32                                               0.992       \n",
       "44                                               0.942       \n",
       "101                                              0.900       \n",
       "100                                              0.884       \n",
       "78                                               0.968       \n",
       "\n",
       "     pan24-generative-authorship-test-b-20240506-test (Mean)  \\\n",
       "1                                                  NaN         \n",
       "57                                               0.989         \n",
       "58                                               0.989         \n",
       "102                                              0.963         \n",
       "29                                               0.972         \n",
       "63                                               0.966         \n",
       "35                                               0.984         \n",
       "37                                               0.988         \n",
       "34                                               0.968         \n",
       "39                                               0.987         \n",
       "76                                               0.966         \n",
       "33                                               0.960         \n",
       "65                                               0.968         \n",
       "66                                               0.968         \n",
       "62                                               0.951         \n",
       "75                                               0.951         \n",
       "56                                               0.947         \n",
       "72                                               0.945         \n",
       "70                                               0.968         \n",
       "24                                               0.926         \n",
       "32                                                 NaN         \n",
       "44                                               0.932         \n",
       "101                                              0.895         \n",
       "100                                              0.877         \n",
       "78                                               0.959         \n",
       "\n",
       "     pan24-generative-authorship-news-test-c-20240506-test (Mean)  \\\n",
       "1                                                0.983              \n",
       "57                                               0.965              \n",
       "58                                               0.965              \n",
       "102                                              0.978              \n",
       "29                                               0.928              \n",
       "63                                               0.990              \n",
       "35                                               0.798              \n",
       "37                                               0.874              \n",
       "34                                               0.886              \n",
       "39                                               0.815              \n",
       "76                                               0.781              \n",
       "33                                               0.823              \n",
       "65                                               0.837              \n",
       "66                                               0.837              \n",
       "62                                               0.977              \n",
       "75                                               0.820              \n",
       "56                                               0.884              \n",
       "72                                               0.979              \n",
       "70                                               0.681              \n",
       "24                                               0.947              \n",
       "32                                               0.698              \n",
       "44                                               0.951              \n",
       "101                                              0.950              \n",
       "100                                              0.912              \n",
       "78                                               0.514              \n",
       "\n",
       "     pan24-generative-authorship-news-test-d-20240506-test (Mean)  \\\n",
       "1                                                0.955              \n",
       "57                                               0.933              \n",
       "58                                               0.933              \n",
       "102                                              0.975              \n",
       "29                                               0.781              \n",
       "63                                               0.959              \n",
       "35                                               0.829              \n",
       "37                                               0.732              \n",
       "34                                               0.807              \n",
       "39                                               0.764              \n",
       "76                                               0.986              \n",
       "33                                               0.777              \n",
       "65                                               0.820              \n",
       "66                                               0.820              \n",
       "62                                               0.849              \n",
       "75                                               0.942              \n",
       "56                                               0.859              \n",
       "72                                               0.848              \n",
       "70                                               0.711              \n",
       "24                                               0.880              \n",
       "32                                               0.561              \n",
       "44                                               0.631              \n",
       "101                                              0.951              \n",
       "100                                              0.906              \n",
       "78                                               0.839              \n",
       "\n",
       "     pan24-generative-authorship-news-test-e-20240506-test (Mean)  \\\n",
       "1                                                0.986              \n",
       "57                                               0.936              \n",
       "58                                               0.936              \n",
       "102                                              0.987              \n",
       "29                                               0.986              \n",
       "63                                               0.743              \n",
       "35                                               0.954              \n",
       "37                                               0.932              \n",
       "34                                               0.815              \n",
       "39                                               0.947              \n",
       "76                                               0.858              \n",
       "33                                               0.942              \n",
       "65                                               0.875              \n",
       "66                                               0.878              \n",
       "62                                               0.659              \n",
       "75                                               0.791              \n",
       "56                                               0.835              \n",
       "72                                               0.601              \n",
       "70                                               0.968              \n",
       "24                                               0.896              \n",
       "32                                               0.951              \n",
       "44                                               0.570              \n",
       "101                                              0.547              \n",
       "100                                              0.830              \n",
       "78                                               0.786              \n",
       "\n",
       "     pan24-generative-authorship-news-test-f-20240514-test (Mean)  \\\n",
       "1                                                0.993              \n",
       "57                                               0.989              \n",
       "58                                               0.989              \n",
       "102                                              0.958              \n",
       "29                                               0.960              \n",
       "63                                               0.993              \n",
       "35                                               0.975              \n",
       "37                                               0.990              \n",
       "34                                               0.981              \n",
       "39                                               0.989              \n",
       "76                                               0.913              \n",
       "33                                               0.937              \n",
       "65                                               0.931              \n",
       "66                                               0.931              \n",
       "62                                               0.985              \n",
       "75                                               0.937              \n",
       "56                                               0.961              \n",
       "72                                               0.978              \n",
       "70                                               0.934              \n",
       "24                                               0.922              \n",
       "32                                               0.987              \n",
       "44                                               0.979              \n",
       "101                                              0.922              \n",
       "100                                              0.874              \n",
       "78                                               0.894              \n",
       "\n",
       "     pan24-generative-authorship-news-test-g-20240529-test (Mean)  \\\n",
       "1                                                1.000              \n",
       "57                                               0.999              \n",
       "58                                               0.999              \n",
       "102                                              0.970              \n",
       "29                                               0.976              \n",
       "63                                               0.996              \n",
       "35                                               0.995              \n",
       "37                                               0.998              \n",
       "34                                               0.996              \n",
       "39                                               1.000              \n",
       "76                                               0.995              \n",
       "33                                               0.948              \n",
       "65                                               0.996              \n",
       "66                                               0.996              \n",
       "62                                               0.990              \n",
       "75                                               0.984              \n",
       "56                                               0.972              \n",
       "72                                               0.991              \n",
       "70                                               0.973              \n",
       "24                                               0.936              \n",
       "32                                               0.996              \n",
       "44                                               1.000              \n",
       "101                                              0.950              \n",
       "100                                              0.891              \n",
       "78                                               0.997              \n",
       "\n",
       "     pan24-generative-authorship-news-test-h-20240521-test (Mean)  \\\n",
       "1                                                0.887              \n",
       "57                                               0.883              \n",
       "58                                               0.883              \n",
       "102                                              0.826              \n",
       "29                                                 NaN              \n",
       "63                                               0.863              \n",
       "35                                                 NaN              \n",
       "37                                                 NaN              \n",
       "34                                                 NaN              \n",
       "39                                               0.832              \n",
       "76                                               0.770              \n",
       "33                                                 NaN              \n",
       "65                                               0.696              \n",
       "66                                               0.697              \n",
       "62                                               0.751              \n",
       "75                                               0.674              \n",
       "56                                               0.668              \n",
       "72                                               0.859              \n",
       "70                                               0.721              \n",
       "24                                               0.527              \n",
       "32                                                 NaN              \n",
       "44                                                 NaN              \n",
       "101                                              0.791              \n",
       "100                                              0.695              \n",
       "78                                               0.780              \n",
       "\n",
       "     pan24-generative-authorship-eloquent-20240523-test (Mean)  \\\n",
       "1                                                0.999           \n",
       "57                                               0.976           \n",
       "58                                               0.976           \n",
       "102                                              0.944           \n",
       "29                                               0.942           \n",
       "63                                               0.984           \n",
       "35                                               0.958           \n",
       "37                                               0.939           \n",
       "34                                               0.960           \n",
       "39                                               0.961           \n",
       "76                                               0.991           \n",
       "33                                               0.940           \n",
       "65                                               0.992           \n",
       "66                                               0.986           \n",
       "62                                               0.964           \n",
       "75                                               0.996           \n",
       "56                                               0.927           \n",
       "72                                               0.870           \n",
       "70                                               0.944           \n",
       "24                                               0.916           \n",
       "32                                               0.958           \n",
       "44                                               0.978           \n",
       "101                                              0.873           \n",
       "100                                              0.821           \n",
       "78                                               0.984           \n",
       "\n",
       "     arithmetic_mean  geometric_mean  \n",
       "1           0.975125        0.974429  \n",
       "57          0.962222        0.961536  \n",
       "58          0.962222        0.961536  \n",
       "102         0.952556        0.951345  \n",
       "29          0.939875        0.937582  \n",
       "63          0.940000        0.936270  \n",
       "35          0.935375        0.932430  \n",
       "37          0.930000        0.925748  \n",
       "34          0.922875        0.920002  \n",
       "39          0.920556        0.916360  \n",
       "76          0.914778        0.910603  \n",
       "33          0.911375        0.908839  \n",
       "65          0.898889        0.893479  \n",
       "66          0.898778        0.893460  \n",
       "62          0.897444        0.889619  \n",
       "75          0.894333        0.887934  \n",
       "56          0.888778        0.883672  \n",
       "72          0.891111        0.882329  \n",
       "70          0.874556        0.865489  \n",
       "24          0.875778        0.864057  \n",
       "32          0.877571        0.859990  \n",
       "44          0.872875        0.855725  \n",
       "101         0.864333        0.853668  \n",
       "100         0.854444        0.851872  \n",
       "78          0.857889        0.843111  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('geometric_mean', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db58adbe-76ae-4245-ac52-5c3619e85e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>team</th>\n",
       "      <th>pan24-generative-authorship-test-20240502-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-test-b-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-c-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-d-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-e-20240506-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-f-20240514-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-g-20240516-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-news-test-h-20240521-test (Mean)</th>\n",
       "      <th>pan24-generative-authorship-eloquent-20240523-test (Mean)</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>geometric_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bayes-fsu-count-vectorizer</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.864444</td>\n",
       "      <td>0.853768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>bayes-fsu-tfidf-vectorizer</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.854333</td>\n",
       "      <td>0.851766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>baseline-binoculars</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>0.802635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>baseline-fastdetectgpt-mistral</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.778222</td>\n",
       "      <td>0.673658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>baseline-binoculars-mistral</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.771111</td>\n",
       "      <td>0.678370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>baseline-length</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.680935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>baseline-ppmd</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.669778</td>\n",
       "      <td>0.635906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>baseline-unmasking</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.646889</td>\n",
       "      <td>0.620883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>baseline-fastdetectgpt</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.639667</td>\n",
       "      <td>0.580112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          approach      team  \\\n",
       "96      bayes-fsu-count-vectorizer  baseline   \n",
       "95      bayes-fsu-tfidf-vectorizer  baseline   \n",
       "90             baseline-binoculars  baseline   \n",
       "94  baseline-fastdetectgpt-mistral  baseline   \n",
       "89     baseline-binoculars-mistral  baseline   \n",
       "92                 baseline-length  baseline   \n",
       "93                   baseline-ppmd  baseline   \n",
       "91              baseline-unmasking  baseline   \n",
       "88          baseline-fastdetectgpt  baseline   \n",
       "\n",
       "    pan24-generative-authorship-test-20240502-test (Mean)  \\\n",
       "96                                              0.900       \n",
       "95                                              0.884       \n",
       "90                                              0.965       \n",
       "94                                              0.866       \n",
       "89                                              0.913       \n",
       "92                                              0.683       \n",
       "93                                              0.770       \n",
       "91                                              0.697       \n",
       "88                                              0.704       \n",
       "\n",
       "    pan24-generative-authorship-test-b-20240506-test (Mean)  \\\n",
       "96                                              0.895         \n",
       "95                                              0.877         \n",
       "90                                              0.962         \n",
       "94                                              0.838         \n",
       "89                                              0.913         \n",
       "92                                              0.661         \n",
       "93                                              0.750         \n",
       "91                                              0.696         \n",
       "88                                              0.677         \n",
       "\n",
       "    pan24-generative-authorship-news-test-c-20240506-test (Mean)  \\\n",
       "96                                              0.950              \n",
       "95                                              0.912              \n",
       "90                                              0.841              \n",
       "94                                              0.842              \n",
       "89                                              0.700              \n",
       "92                                              0.693              \n",
       "93                                              0.752              \n",
       "91                                              0.673              \n",
       "88                                              0.719              \n",
       "\n",
       "    pan24-generative-authorship-news-test-d-20240506-test (Mean)  \\\n",
       "96                                              0.951              \n",
       "95                                              0.906              \n",
       "90                                              0.342              \n",
       "94                                              0.095              \n",
       "89                                              0.112              \n",
       "92                                              0.695              \n",
       "93                                              0.270              \n",
       "91                                              0.662              \n",
       "88                                              0.159              \n",
       "\n",
       "    pan24-generative-authorship-news-test-e-20240506-test (Mean)  \\\n",
       "96                                              0.547              \n",
       "95                                              0.830              \n",
       "90                                              0.818              \n",
       "94                                              0.958              \n",
       "89                                              0.878              \n",
       "92                                              0.920              \n",
       "93                                              0.742              \n",
       "91                                              0.735              \n",
       "88                                              0.982              \n",
       "\n",
       "    pan24-generative-authorship-news-test-f-20240514-test (Mean)  \\\n",
       "96                                              0.922              \n",
       "95                                              0.874              \n",
       "90                                              0.844              \n",
       "94                                              0.793              \n",
       "89                                              0.774              \n",
       "92                                              0.619              \n",
       "93                                              0.546              \n",
       "91                                              0.651              \n",
       "88                                              0.418              \n",
       "\n",
       "    pan24-generative-authorship-news-test-g-20240516-test (Mean)  \\\n",
       "96                                              0.951              \n",
       "95                                              0.890              \n",
       "90                                              0.996              \n",
       "94                                              0.931              \n",
       "89                                              0.942              \n",
       "92                                              0.554              \n",
       "93                                              0.843              \n",
       "91                                              0.696              \n",
       "88                                              0.712              \n",
       "\n",
       "    pan24-generative-authorship-news-test-h-20240521-test (Mean)  \\\n",
       "96                                              0.791              \n",
       "95                                              0.695              \n",
       "90                                              0.756              \n",
       "94                                              0.738              \n",
       "89                                              0.808              \n",
       "92                                              0.692              \n",
       "93                                              0.492              \n",
       "91                                              0.250              \n",
       "88                                              0.579              \n",
       "\n",
       "    pan24-generative-authorship-eloquent-20240523-test (Mean)  \\\n",
       "96                                              0.873           \n",
       "95                                              0.821           \n",
       "90                                              0.996           \n",
       "94                                              0.943           \n",
       "89                                              0.900           \n",
       "92                                              0.663           \n",
       "93                                              0.863           \n",
       "91                                              0.762           \n",
       "88                                              0.807           \n",
       "\n",
       "    arithmetic_mean  geometric_mean  \n",
       "96         0.864444        0.853768  \n",
       "95         0.854333        0.851766  \n",
       "90         0.835556        0.802635  \n",
       "94         0.778222        0.673658  \n",
       "89         0.771111        0.678370  \n",
       "92         0.686667        0.680935  \n",
       "93         0.669778        0.635906  \n",
       "91         0.646889        0.620883  \n",
       "88         0.639667        0.580112  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['team'] == 'baseline'].sort_values('arithmetic_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c8db45c-a709-4eeb-9d92-9fe42fb7f13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tira\n",
      "  Downloading tira-0.0.129-py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.4/91.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from tira) (1.5.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tira) (4.64.1)\n",
      "Requirement already satisfied: requests==2.*,>=2.26 in /opt/conda/lib/python3.10/site-packages (from tira) (2.28.1)\n",
      "Collecting docker==6.*,>=6.0.0\n",
      "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from docker==6.*,>=6.0.0->tira) (1.4.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker==6.*,>=6.0.0->tira) (1.26.11)\n",
      "Requirement already satisfied: packaging>=14.0 in /opt/conda/lib/python3.10/site-packages (from docker==6.*,>=6.0.0->tira) (21.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests==2.*,>=2.26->tira) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests==2.*,>=2.26->tira) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests==2.*,>=2.26->tira) (2022.9.24)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->tira) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->tira) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas->tira) (1.23.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=14.0->docker==6.*,>=6.0.0->tira) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->tira) (1.16.0)\n",
      "Installing collected packages: docker, tira\n",
      "Successfully installed docker-6.1.3 tira-0.0.129\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tira"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff477ecf-6740-4899-a3ea-9f99072c5477",
   "metadata": {},
   "source": [
    "# Create `evaluation-scores.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d832a76f-afdc-4426-8077-2b9f5b761247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.rest_api_client import Client\n",
    "tira = Client()\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_evaluation(team, dataset, software):\n",
    "    ret = tira.download_evaluation(task, dataset, software, team)\n",
    "    return json.load(open(f'{ret}/evaluation.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08a6050c-a251-4732-a50b-4d31398fbff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process pan24-generative-authorship-test-20240502-test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  8.61it/s]\n",
      "Process pan24-generative-authorship-test-b-20240506-test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.88it/s]\n",
      "Process pan24-generative-authorship-news-test-c-20240506-test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.20it/s]\n",
      "Process pan24-generative-authorship-news-test-d-20240506-test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.41it/s]\n",
      "Process pan24-generative-authorship-news-test-e-20240506-test:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                 | 9/32 [00:03<00:05,  4.32it/s]\n",
      "Download: 22.0iB [00:00, 14.7kiB/s]\n",
      "Process pan24-generative-authorship-news-test-e-20240506-test:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 21/32 [00:03<00:01, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /home/jovyan/.tira/extracted_runs/generative-ai-authorship-verification-panclef-2024/pan24-generative-authorship-news-test-e-20240506-test/j1j\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process pan24-generative-authorship-news-test-e-20240506-test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  8.06it/s]\n",
      "Process pan24-generative-authorship-news-test-f-20240514-test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.98it/s]\n",
      "Process pan24-generative-authorship-news-test-g-20240529-test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.01it/s]\n",
      "Process pan24-generative-authorship-news-test-h-20240521-test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.62it/s]\n",
      "Process pan24-generative-authorship-eloquent-20240523-test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.80it/s]\n"
     ]
    }
   ],
   "source": [
    "ret = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for team, approaches in tqdm(TEAM_TO_SUBMISSIONS.items(), 'Process ' + dataset):\n",
    "        for approach in approaches:\n",
    "            if team not in ret:\n",
    "                ret[team] = {}\n",
    "            if approach not in ret[team]:\n",
    "                ret[team][approach] = {}\n",
    "\n",
    "            try:\n",
    "                ret[team][approach][dataset] = load_evaluation(team, dataset, approach)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "json.dump(ret, open('evaluation-scores.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
